{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Recognition via Vietoris-Rips Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csgraph\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_index(k, i, j):\n",
    "    \"\"\"Calculate index of a vertice: g(v_{k,i,j}) = (k + 1) * i + j + sum_{l=0}^{k} l^2\n",
    "\n",
    "    Args:\n",
    "        k (int): Length of the side of the square. -1!\n",
    "        i (int): Row index of left top the square in a image.\n",
    "        j (int): Column index of left top the square in a image.\n",
    "\n",
    "    Returns:\n",
    "        int: The index of the vertice.\n",
    "    \"\"\"    \n",
    "    index = (k + 1) * i + j + np.array([l**2 for l in range(k+1)]).sum()\n",
    "    return index\n",
    "\n",
    "def get_vertice(image, k, i, j):\n",
    "    \"\"\"Get a square (a vertice in the graph) from a given image.\n",
    "       v_{k,i,j} = [N, N - k, i] * [N, N - k, j] in V_{N, N}\n",
    "\n",
    "    Args:\n",
    "        image (np.array): N * N gray scale image.\n",
    "        k (int): Length of the side of the square.\n",
    "        i (int): Row index of left top the square in a image.\n",
    "        j (int): Column index of left top the square in a image.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A k * k gray scale sub-image.\n",
    "    \"\"\"    \n",
    "    square_width = image.shape[0] - k\n",
    "    vertice = image[i:(i + square_width), j:(j + square_width)]\n",
    "    return vertice\n",
    "\n",
    "def calc_weight(vertice_1, vertice_2):\n",
    "    \"\"\"Calculate the weight of the edge between two given vertices.\n",
    "       w_f({v_1, v_2}) = |#f(v_2) = #f(v_1)|, where #f(v) is the number of colors of v.\n",
    "\n",
    "    Args:\n",
    "        vertice_1 (np.array[int]): A gray scale sub-image (vertice 1).\n",
    "        vertice_2 (np.array[int]): A gray scale sub-image (vertice 2).\n",
    "\n",
    "    Returns:\n",
    "        int: Weight of the edge.\n",
    "    \"\"\"    \n",
    "    weight = abs(np.unique(vertice_1).size - np.unique(vertice_2).size)\n",
    "    return weight\n",
    "\n",
    "# def assign_values_to_list(k, i, j, vertices_from_list, vertices_to_list, weights_list, image):\n",
    "#     vertices_from_list.append(calc_index(k, i, j))\n",
    "#     vertices_to_list.append(calc_index(k + 1, i, j))\n",
    "#     weights_list.append(calc_weight(get_vertice(image, k, i, j), get_vertice(image, k + 1, i, j)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the 1-Skelton of the Vietoris-Rips Complex Using All Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_one_skelton(image, small_epsilon=0.0):\n",
    "    \"\"\"Construct 1-skelton of the Vietoris-Rips Complex using all squares of a image.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): N * N gray scale image.\n",
    "        small_epsilon (float, optional): Small constant. If weights are under this values, weights will be 1 else be 0.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List, List, List]: V_from (Index list of vertices), V_to (Index list of vertices), tilde{W} (Binarized weight list)\n",
    "    \"\"\"    \n",
    "    image_size = image.shape[0]\n",
    "    vertices_from_list = []\n",
    "    vertices_to_list = []\n",
    "    weights_list = []\n",
    "    weights_tilde_list = []\n",
    "\n",
    "    for k in tqdm(range(image_size -1)):\n",
    "        for i in range(k + 1):\n",
    "            for j in range(k + 1):\n",
    "                index_k_i_j = calc_index(k, i, j)\n",
    "\n",
    "                vertices_from_list.append(index_k_i_j)\n",
    "                vertices_to_list.append(calc_index(k + 1, i, j))\n",
    "                weights_list.append(calc_weight(get_vertice(image, k, i, j), get_vertice(image, k + 1, i, j)))\n",
    "\n",
    "                # TODO: 関数化\n",
    "                vertices_from_list.append(index_k_i_j)\n",
    "                vertices_to_list.append(calc_index(k + 1, i, j + 1))\n",
    "                weights_list.append(calc_weight(get_vertice(image, k, i, j), get_vertice(image, k + 1, i, j + 1)))\n",
    "\n",
    "                vertices_from_list.append(index_k_i_j)\n",
    "                vertices_to_list.append(calc_index(k + 1, i + 1, j))\n",
    "                weights_list.append(calc_weight(get_vertice(image, k, i, j), get_vertice(image, k + 1, i + 1, j)))\n",
    "\n",
    "                vertices_from_list.append(index_k_i_j)\n",
    "                vertices_to_list.append(calc_index(k + 1, i + 1, j + 1))\n",
    "                weights_list.append(calc_weight(get_vertice(image, k, i, j), get_vertice(image, k + 1, i + 1, j + 1)))  \n",
    "\n",
    "    for weight in weights_list:\n",
    "        if weight > small_epsilon:\n",
    "            weights_tilde_list.append(0)\n",
    "        else:\n",
    "            weights_tilde_list.append(1)\n",
    "\n",
    "    return vertices_from_list, vertices_to_list, weights_tilde_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting Minimal Size Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_ADDRESS = 'img/tea.png'\n",
    "IMAGE_RESIZE = (10, 10)\n",
    "\n",
    "pil_image = Image.open(IMAGE_ADDRESS)\n",
    "pil_image = pil_image.resize(IMAGE_RESIZE).convert('L')\n",
    "image = np.array(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 249.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 7639.90it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate minimal size squares and run object detection based on the result.\n",
    "\"\"\"\n",
    "vertices_from_list, vertices_to_list, weights_tilde_list = construct_one_skelton(image, small_epsilon=0)\n",
    "\n",
    "# 縦がV_from、横がV_toで重みがW_tildeとなるグラフをCSR形式で作る\n",
    "compressed_sparse_matrix = csr_matrix((weights_tilde_list, (vertices_from_list, vertices_to_list)), shape = (max(vertices_to_list) + 1, max(vertices_to_list) + 1))\n",
    "connected_components = csgraph.connected_components(compressed_sparse_matrix)[1]\n",
    "\n",
    "vertice_tmp = 0\n",
    "for index, connected_component in enumerate(connected_components):\n",
    "    if connected_component == 0:\n",
    "        vertice_tmp = index\n",
    "\n",
    "N = image.shape[0]\n",
    "vector = np.array([l**2 for l in range(N + 1)])\n",
    "k_prime = N - [l for l in range(1,N+1) if vector[:l+1].sum() > vertice_tmp][0]\n",
    "detection_result = np.zeros_like(image)\n",
    "for i in tqdm(range(k_prime + 1)):\n",
    "    for j in range(k_prime + 1):\n",
    "        if connected_components[calc_index(k_prime, i, j)] == 0:\n",
    "            detection_result[i:(i + detection_result.shape[0] - k_prime), j:(j + detection_result.shape[1] - k_prime)] = get_vertice(image, k_prime, i, j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(detection_result, cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "51277dc59fd066300e419e915d8a2a9e32bab27c1c3bc1bdcf4bc7cf23b2a3da"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
